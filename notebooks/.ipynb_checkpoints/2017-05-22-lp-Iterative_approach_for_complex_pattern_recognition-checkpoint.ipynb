{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this notebook i am going to expose the ability of an iterative approach to recognize complex patterns aginst conventional feedfoward approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name linear",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dc146664f866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrnn_cell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name linear"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import floor\n",
    "from rnn_cell import *\n",
    "\n",
    "class IterativeCell(object):\n",
    "\n",
    "    def __init__(self, size, max_iterations=50., initial_iterate_prob=0.5,\n",
    "                 iterate_prob_decay=0.5, allow_cell_reactivation=True, add_summaries=False, device_to_run_at=None):\n",
    "        self._device_to_run_at = device_to_run_at\n",
    "        self._sixe = size\n",
    "\n",
    "        if max_iterations < 1:\n",
    "            raise \"The maximum amount of iterations to perform must be a natural value\"\n",
    "\n",
    "        if initial_iterate_prob <= 0 or initial_iterate_prob >= 1:\n",
    "            raise \"iteration_prob must be a value between 0 and 1\"\n",
    "\n",
    "        self._max_iteration_constant = max_iterations\n",
    "        self._initial_iterate_prob_constant = initial_iterate_prob\n",
    "        self._iterate_prob_decay_constant = iterate_prob_decay\n",
    "        self._allow_reactivation = allow_cell_reactivation\n",
    "        self._should_add_summaries = add_summaries\n",
    "        self._already_added_summaries = []\n",
    "\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        return self._internal_nn._input_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._internal_nn.output_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._internal_nn.state_size\n",
    "\n",
    "    def __call__(self, input, scope=None):\n",
    "        if self._should_add_summaries:\n",
    "            self.add_pre_execution_summaries(input)\n",
    "\n",
    "        with vs.variable_scope(scope or type(self).__name__):\n",
    "            loop_vars = [input, tf.zeros([self.output_size]), tf.constant(0.0),\n",
    "                         tf.constant(self._max_iteration_constant), tf.constant(self._initial_iterate_prob_constant),\n",
    "                         tf.constant(self._iterate_prob_decay_constant), tf.ones(tf.shape(input)), tf.zeros([input.get_shape().dims[0].value, self.output_size]),\n",
    "                         tf.constant(True)]\n",
    "            loop_vars[0], loop_vars[1], loop_vars[2], loop_vars[3], loop_vars[4], loop_vars[5], loop_vars[6], loop_vars[\n",
    "                7], loop_vars[8], loop_vars[9], loop_vars[10] = tf.while_loop(iterativeLSTM_LoopCondition, iterativeLSTM_Iteration, loop_vars)\n",
    "\n",
    "        #_, loop_vars[0] = array_ops.split(1, 2, loop_vars[1])\n",
    "\n",
    "        if self._should_add_summaries:\n",
    "            self.add_post_execution_summaries(input, state, loop_vars[0] , loop_vars[1], loop_vars[4], None, loop_vars[9], None)\n",
    "\n",
    "        return loop_vars[0]\n",
    "\n",
    "    def add_pre_execution_summaries(self, input, state):\n",
    "        if not self._already_added_summaries.__contains__(tf.get_variable_scope().name +\n",
    "                                                                  \"/pre_execution_input_entropy\"):\n",
    "            variable_summaries(calculate_feature_entropy(input),\n",
    "                               tf.get_variable_scope().name + \"/pre_execution_input_entropy\", add_histogram=False)\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name + \"/pre_execution_input_entropy\")\n",
    "\n",
    "    def add_post_execution_summaries(self, initial_input, initial_state, final_output, final_state, number_of_iterations_performed,\n",
    "                                     final_iterate_prob, final_iterations_counts, final_iteration_activations):\n",
    "        if not self._already_added_summaries.__contains__(tf.get_variable_scope().name+\"/iterations_performed\"):\n",
    "            variable_summaries(number_of_iterations_performed, tf.get_variable_scope().name+\"/iterations_performed\")\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name+\"/iterations_performed\")\n",
    "\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name+\"/iterations_counts\")\n",
    "            variable_summaries(final_iterations_counts, tf.get_variable_scope().name+\"/iterations_counts\")\n",
    "\n",
    "            variable_summaries(calculate_feature_entropy(final_output),\n",
    "                               tf.get_variable_scope().name + \"/post_execution_output_entropy\", add_histogram=False)\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name + \"/post_execution_output_entropy\")\n",
    "\n",
    "            variable_summaries(calculate_feature_vectors_kl_divergence(initial_input, final_output),\n",
    "                               tf.get_variable_scope().name + \"/improved_from_former_kl_divergence\", add_histogram=False)\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name + \"/improved_from_former_kl_divergence\")\n",
    "\n",
    "            variable_summaries(calculate_feature_vectors_kl_divergence(final_output, initial_input),\n",
    "                               tf.get_variable_scope().name + \"/former_from_improved_kl_divergence\", add_histogram=False)\n",
    "            self._already_added_summaries.append(tf.get_variable_scope().name + \"/former_from_improved_kl_divergence\")\n",
    "\n",
    "def calculate_feature_entropy(feature_vector):\n",
    "    return - feature_vector * tf.log(feature_vector) - (1 - feature_vector) * tf.log(1 - feature_vector)\n",
    "\n",
    "def calculate_feature_vectors_kl_divergence(former_feature_vector, updated_feature_vector):\n",
    "    return former_feature_vector * (tf.log(former_feature_vector) - tf.log(updated_feature_vector)) + (1 - former_feature_vector) * (tf.log(1 - former_feature_vector) - tf.log(1 - updated_feature_vector))\n",
    "\n",
    "\n",
    "def iterativeLSTM_Iteration(inputs, num_units, iteration_number, max_iterations,\n",
    "                            iteration_prob, iteration_prob_decay, iteration_activation, iteration_count, \n",
    "                            keep_looping):\n",
    "\n",
    "    output, new_iteration_activation = iterativeLSTM(inputs, state, num_units.get_shape().dims[0].value,\n",
    "                                                                                        forget_bias, iteration_activation,\n",
    "                                                                                        iteration_count, iteration_prob)\n",
    "    iteration_flag = tf.reduce_max(new_iteration_activation)\n",
    "\n",
    "    iteration_count = iteration_count + iteration_flag\n",
    "\n",
    "    new_iteration_number = iteration_number + iteration_flag\n",
    "\n",
    "    do_keep_looping = tf.logical_and(tf.less(new_iteration_number, max_iterations), tf.equal(iteration_flag, tf.constant(1.0)))\n",
    "\n",
    "    new_iteration_prob = iteration_prob * iteration_prob_decay\n",
    "\n",
    "    #new_c, new_h = array_ops.split(1, 2, new_state)\n",
    "\n",
    "    new_output = tf.cond(do_keep_looping, lambda: inputs, lambda: output)\n",
    "\n",
    "    return output, new_state, num_units, forget_bias, new_iteration_number, max_iterations, new_iteration_prob, iteration_prob_decay, new_iteration_activation, iteration_count, do_keep_looping\n",
    "\n",
    "def iterativeLSTM_LoopCondition(inputs, num_units, iteration_number, max_iterations,\n",
    "                                iteration_prob, iteration_prob_decay, iteration_activation, iteration_count, \n",
    "                                keep_looping):\n",
    "    return keep_looping\n",
    "\n",
    "\n",
    "def iterative_cell(inputs, num_units, iteration_activation, iteration_count, iteration_prob):\n",
    "    j_logits = linear([inputs], num_units, False, scope=\"j_logits\")\n",
    "    j_displacement = linear([iteration_count], num_units, True, scope=\"j_displacement\")\n",
    "    opposed_j = tanh( - j_logits + j_displacement)\n",
    "    new_info = tanh(tanh(j_logits + j_displacement) + tanh(opposed_j * sigmoid(opposed_j)))\n",
    "    logits = linear([new_info], num_units, True)\n",
    "\n",
    "    new_output = logits * iteration_activation + inputs * (1 - iteration_activation)\n",
    "\n",
    "    # In this approach the evidence of the iteration gate is based on the inputs that doesn't change over iterations and its state\n",
    "    p = linear([inputs, new_output], num_units, True, scope= \"iteration_activation\")\n",
    "\n",
    "\n",
    "    new_iteration_activation = update_iteration_activations(iteration_activation, floor(sigmoid(p) + iteration_prob))\n",
    "\n",
    "    return new_output, new_state, new_iteration_activation\n",
    "\n",
    "def update_iteration_activations(current_iteration_activations, new_iteration_activations):\n",
    "    # It is possible that other instances of the batch activate this cell, hence we need to avoid this\n",
    "    # by activate only those activations were this instance of the batch is actually activated\n",
    "    batch_iteration_activations = tf.reduce_max(current_iteration_activations, 1, True)\n",
    "    batch_iteration_activations_extended = tf.tile(batch_iteration_activations,\n",
    "        [1, int(current_iteration_activations.get_shape().dims[1].value\n",
    "            or new_iteration_activations.get_shape().dims[1].value)])\n",
    "\n",
    "    return new_iteration_activations * batch_iteration_activations_extended\n",
    "\n",
    "\n",
    "def variable_summaries(var, name, add_distribution=True, add_range=True, add_histogram=True):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        if add_distribution:\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.scalar_summary('mean/' + name, mean)\n",
    "            with tf.name_scope('stddev'):\n",
    "                stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "                tf.scalar_summary('sttdev/' + name, stddev)\n",
    "\n",
    "        if add_range:\n",
    "            tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "            tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "\n",
    "        if add_histogram:\n",
    "            tf.histogram_summary(name, var)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
